{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLADS 2019 - Deep Learning for NLP Applications: Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D CNN's for Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural Network - Key components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a neural network revolves around the following objects:\n",
    "\n",
    "- Layer, which are combined into a network or model\n",
    "- Input data, and the corresponding targets\n",
    "- Loss function, which defines the feedback signal\n",
    "- Optimizer, which determines how the learning proceeds\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between network, layers, loss function and optimizer\n",
    "\n",
    "![title](figures/NN_Anatomy_color.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers: The building blocks of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer is a data processing module that takes as input one or more tensors and outputs one or more tensors\n",
    "- More frequently, layers have a state: layer's weights (learned via the optimizer)\n",
    "- Types of Layers - Embedding, Densely connected, Dropout, convolutional, Pooling, Recurrent\n",
    "- Layers are almost like LEGO bricks of deep learning, that is made explicit by Keras\n",
    "- Layer compatibility refers to the fact that every layer will only accept input tensors of a certain shape and will return output tensors of a certain shape\n",
    "\n",
    "#### Building deep learing models in Keras is done by joining together compatible layers to form useful data-transformation pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential model is a linear stack of layers\n",
    "\n",
    "- You can instantiate a Sequential model object and then add layers using the .add() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# Define the model architecture in terms of layers\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#Print out the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ImDB Movie Reviews Classification with Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sequential model\n",
    "from keras.models import Sequential\n",
    "\n",
    "#import needed layers\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "# import dataset\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# For preprocessing text\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up parameters for reading the textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "max_features: Number of words to consider as features (Vocabulary)\n",
    "\n",
    "maxlen: Cuts off text after this number of words (among the max_features most common words)\n",
    "\n",
    "'''\n",
    "\n",
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 400\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load the data as a list of integers\n",
    "'''\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "- The argument max_features = 5,000 means you will only keep the top 5,000 most frequently used words in the training data, and rare words will be discarded. \n",
    "\n",
    "- The argument maxlen = 400 means we will only keep the first 400 words in the review and postpad (or prepad) if the review is shorter than 400 words\n",
    "\n",
    "- x_train and x_test are lists of reviews; each review is a list of word indices (encoding a sequence of words)\n",
    "\n",
    "- y_train and y_test are lists of 0's and 1's (0: negative and 1: positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example to illustrate the preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figures/preprocess_text.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1  Training and evaluating a simple 1D convnet on the IMDB data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration of the network architecture we will be using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figures/network_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "embedding dims: Dimensionality of the vector representing each word\n",
    "'''\n",
    "\n",
    "embedding_dims = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "- __max_features__: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-5000, then the size of the vocabulary would be 5000 words.\n",
    "- __embedding_dims__: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "- __input_length__: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are reduced to 400 words, this would be 400."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration of the embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figures/embedding_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_filters = 250\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(num_filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figures/conv_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_dims = 250\n",
    "epochs = 2\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 398, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims)) #hidden_dims = 250\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 11s 545us/step - loss: 0.4092 - acc: 0.7879 - val_loss: 0.3065 - val_acc: 0.8688\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 5s 272us/step - loss: 0.2036 - acc: 0.9216 - val_loss: 0.2748 - val_acc: 0.8888\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plotting training and test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The call to model.fit() returns a history object\n",
    "- This has a member \"history\", which is a dictionary containing everything that happened during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78790000000000004, 0.92164999999999997]\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "print(history_dict['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did we run only for 2 epochs? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Had already run it previously for 6 epochs, and this particular model starts overfitting after 2 epochs\n",
    "\n",
    "![title](figures/acc_vs_epoch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating results on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 79us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28157164542436602, 0.88151999999999997]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
