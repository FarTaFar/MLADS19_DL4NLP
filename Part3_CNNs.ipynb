{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLADS 2019 - Deep Learning for NLP Applications: Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D CNN's for Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural Network - Key components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a neural network revolves around the following objects:\n",
    "\n",
    "- Layer, which are combined into a network or model\n",
    "- Input data, and the corresponding targets\n",
    "- Loss function, which defines the feedback signal\n",
    "- Optimizer, which determines how the learning proceeds\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between network, layers, loss function and optimizer\n",
    "\n",
    "![title](figures/NN_Anatomy_color.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers: The building blocks of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer is a data processing module that takes as input one or more tensors and outputs one or more tensors\n",
    "- More frequently, layers have a state: layer's weights (learned via the optimizer)\n",
    "- Types of Layers - Embedding, Densely connected, Dropout, convolutional, Pooling, Recurrent\n",
    "- Layers are almost like LEGO bricks of deep learning, that is made explicit by Keras\n",
    "- Layer compatibility refers to the fact that every layer will only accept input tensors of a certain shape and will return output tensors of a certain shape\n",
    "\n",
    "#### Building deep learing models in Keras is done by joining together compatible layers to form useful data-transformation pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential model is a linear stack of layers\n",
    "\n",
    "- You can instantiate a Sequential model object and then add layers using the .add() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1119 10:47:30.078114  3432 deprecation_wrapper.py:119] From C:\\Users\\fatajadd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1119 10:47:30.166323  3432 deprecation_wrapper.py:119] From C:\\Users\\fatajadd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1119 10:47:30.180380  3432 deprecation_wrapper.py:119] From C:\\Users\\fatajadd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# Define the model architecture in terms of layers\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#Print out the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ImDB Movie Reviews Classification with Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sequential model\n",
    "from keras.models import Sequential\n",
    "\n",
    "#import needed layers\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "# import dataset\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# For preprocessing text\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up parameters for reading the textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "max_features: Number of words to consider as features (Vocabulary)\n",
    "\n",
    "maxlen: Cuts off text after this number of words (among the max_features most common words)\n",
    "\n",
    "'''\n",
    "\n",
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 400\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load the data as a list of integers\n",
    "'''\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "- The argument max_features = 5,000 means you will only keep the top 5,000 most frequently used words in the training data, and rare words will be discarded. \n",
    "\n",
    "- The argument maxlen = 400 means we will only keep the first 400 words in the review and postpad (or prepad) if the review is shorter than 400 words\n",
    "\n",
    "- x_train and x_test are lists of reviews; each review is a list of word indices (encoding a sequence of words)\n",
    "\n",
    "- y_train and y_test are lists of 0's and 1's (0: negative and 1: positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example to illustrate the preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figures/preprocess_text.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1  Training and evaluating a simple 1D convnet on the IMDB data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration of the network architecture we will be using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figures/network_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "embedding dims: Dimensionality of the vector representing each word\n",
    "'''\n",
    "\n",
    "embedding_dims = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "- __max_features__: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-5000, then the size of the vocabulary would be 5000 words.\n",
    "- __embedding_dims__: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "- __input_length__: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are reduced to 400 words, this would be 400."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration of the embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figures/embedding_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 250\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(num_filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figures/conv_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = 250\n",
    "epochs = 2\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 398, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims)) #hidden_dims = 250\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 10:47:42.410364  3432 deprecation_wrapper.py:119] From C:\\Users\\fatajadd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1119 10:47:42.446510  3432 deprecation_wrapper.py:119] From C:\\Users\\fatajadd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1119 10:47:42.462574  3432 deprecation.py:323] From C:\\Users\\fatajadd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1119 10:47:43.075802  3432 deprecation_wrapper.py:119] From C:\\Users\\fatajadd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 90s 4ms/step - loss: 0.3923 - acc: 0.8093 - val_loss: 0.2828 - val_acc: 0.8802\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 90s 4ms/step - loss: 0.1925 - acc: 0.9243 - val_loss: 0.2726 - val_acc: 0.8898\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plotting training and test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The call to model.fit() returns a history object\n",
    "- This has a member \"history\", which is a dictionary containing everything that happened during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80925, 0.9243]\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "print(history_dict['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did we run only for 2 epochs? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Had already run it previously for 6 epochs, and this particular model starts overfitting after 2 epochs\n",
    "\n",
    "![title](figures/acc_vs_epoch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating results on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 27s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2743025794196129, 0.88748]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
